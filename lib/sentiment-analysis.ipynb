{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nick = {}\n",
    "with open('name_list.txt', 'rb') as f:\n",
    "    for line in f:\n",
    "        if line.strip().partition(\"\\t\")[-1] != '':\n",
    "            nick[line.strip().partition(\"\\t\")[0]] = line.strip().partition(\"\\t\")[0].split(' ')+line.strip().partition(\"\\t\")[-1][1:-1].split(', ')\n",
    "        else:\n",
    "            nick[line.strip().partition(\"\\t\")[0]] = line.strip().partition(\"\\t\")[0].split(' ')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names_v1 = []\n",
    "for x in nick.keys():\n",
    "    with open('sentences2.txt', 'rb') as f:\n",
    "        for line in f:\n",
    "            if x.split(' ')[0].lower() in re.findall(r\"[\\w']+\", line.lower()):\n",
    "                names_v1.append(x)\n",
    "            if nick[x][2:] != []:\n",
    "                for name in nick[x][2:]:\n",
    "                    if set(name.lower().split(' ')).intersection(re.findall(r\"[\\w']+\", line.lower())) ==  set(name.lower().split(' ')):\n",
    "                        names_v1.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allnames = sorted(list(set(names_v1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x in allnames:\n",
    "    if len(x.split(' ')) == 1:\n",
    "        allnames.remove(x)\n",
    "    if (len(x.split(' ')) == 3 and x.split(' ')[-1].lower() == 'potter'):\n",
    "        allnames.remove(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# need to run it again\n",
    "for x in allnames:\n",
    "    if len(x.split(' ')) == 1:\n",
    "        allnames.remove(x)\n",
    "    if (len(x.split(' ')) == 3 and x.split(' ')[-1].lower() == 'potter'):\n",
    "        allnames.remove(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names_set = []\n",
    "for a,b in itertools.combinations(allnames,2):\n",
    "    names_set.append([a,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ep = {}\n",
    "for x in allnames:\n",
    "    ep[x] = nick[x]\n",
    "    \n",
    "#import pickle\n",
    "#with open(\"nick_ep1\", \"wb\") as f:\n",
    "#    pickle.dump(ep1, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m1 = pd.DataFrame(np.zeros(shape=(len(allnames),len(allnames))),index = [range(len(allnames))], columns = [range(len(allnames))])\n",
    "m1.index = allnames\n",
    "m1.columns = allnames\n",
    "\n",
    "m2 = pd.DataFrame(np.zeros(shape=(len(allnames),len(allnames))),index = [range(len(allnames))], columns = [range(len(allnames))])\n",
    "m2.index = allnames\n",
    "m2.columns = allnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "for x,y in names_set:\n",
    "    with open('sentences2.txt', 'rb') as f:\n",
    "        temp1 = 0\n",
    "        temp2 = 0\n",
    "        for line in f:\n",
    "            for name1, name2 in itertools.product(ep[x], ep[y]):\n",
    "                if name1 in ['Mrs Weasley', 'The Grey'] or name2 in ['Mrs Weasley', 'The Grey']:\n",
    "                    if set(name1.lower().split(' ')).intersection(re.findall(r\"[\\w']+\", line.lower())) ==  set(name1.lower().split(' ')) and set(name2.lower().split(' ')).intersection(re.findall(r\"[\\w']+\", line.lower())) ==  set(name2.lower().split(' ')):\n",
    "                        textblob = TextBlob(line.decode('utf8').strip())\n",
    "                        temp1 += textblob.sentiment.polarity\n",
    "                        temp2 += textblob.sentiment.subjectivity \n",
    "                else:\n",
    "                    if name1.lower() in re.findall(r\"[\\w']+\", line.lower()) and name2.lower() in re.findall(r\"[\\w']+\", line.lower()):\n",
    "                        textblob = TextBlob(line.decode('utf8').strip())\n",
    "                        temp1 += textblob.sentiment.polarity\n",
    "                        temp2 += textblob.sentiment.subjectivity \n",
    "                          \n",
    "    m1.loc[x,y] = np.copy(temp1)\n",
    "    m2.loc[x,y] = np.copy(temp2)\n",
    "    m1.loc[y,x] = np.copy(temp1)\n",
    "    m2.loc[y,x] = np.copy(temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "811.8221271038055"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.time()-start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "family_matrix = pd.read_csv(\"book2_co_occurrence.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for r in family_matrix.index:\n",
    "    for c in family_matrix.columns:\n",
    "        if family_matrix.loc[r,c] != 0:\n",
    "            m1.loc[r,c] = m1.loc[r,c]/family_matrix.loc[r,c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for r in family_matrix.index:\n",
    "    for c in family_matrix.columns:\n",
    "        if family_matrix.loc[r,c] != 0:\n",
    "            m2.loc[r,c] = m2.loc[r,c]/family_matrix.loc[r,c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m1.to_csv(\"book2_polarity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m2.to_csv(\"book2_subjectivity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
